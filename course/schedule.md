---
layout: default
---

# Schedule & Readings

---

## Course Schedule

*"The goal isn't to read everything, but to read the right things deeply and connect them meaningfully."*

*AI agents designing the complete computing stack - from code to silicon*

**üìñ Reading Reflection Due**: Before each class session  
**üéØ Discussion Leadership**: Sign up by Week 3

---

### The Thematic Flow:
1. **AI for Software**: Agents understand *what* needs to be computed efficiently
2. **AI for Architecture**: Agents design *how* to compute it efficiently in hardware  
3. **AI for EDA**: Agents implement the architecture *physically* in silicon

---

| Week | Date | Topic | Key Papers |
|------|------|-------|------------|
| **1** | **Sep 3** | **Course Introduction** | |
| | Sep 3 | The AI Agent Revolution in Architecture | Course overview and vision |
| | Sep 4 | Architecture 2.0: Foundational Vision | *A graph placement methodology for fast chip design*<br/>*Chip Placement with Deep Reinforcement Learning* |

## AI for Software
*Software optimization and compilation*

| Week | Date | Topic | Key Papers |
|------|------|-------|------------|
| **2** | **Sep 9** | **AI for Compiler Optimization** | |
| | Sep 9 | CompilerGym and RL for Compilation | TBD |
| | Sep 11 | LLVM and ML-Driven Passes | TBD |
| **3** | **Sep 16** | **AI for Software Generation & Autotuning** | |
| | Sep 16 | TVM and Tensor Compilation | TBD |
| | Sep 18 | Halide and Domain-Specific Languages | TBD |
| **4** | **Sep 23** | **AI for Performance Prediction** | |
| | Sep 23 | Performance Modeling with ML | TBD |
| | Sep 25 | Workload Characterization | TBD |
| **5** | **Sep 30** | **AI for Memory & Data Optimization** | |
| | Sep 30 | Memory Access Pattern Learning | TBD |
| | Oct 2 | Data Layout and Prefetching | TBD |
| **6** | **Oct 7** | **AI for Parallel Code Optimization** | |
| | Oct 7 | Parallel Scheduling and Load Balancing | TBD |
| | Oct 9 | GPU Code Optimization | TBD |

## AI for Architecture
*Hardware design and system architecture*

| Week | Date | Topic | Key Papers |
|------|------|-------|------------|
| **7** | **Oct 14** | **AI for Design Space Exploration** | |
| | Oct 14 | ArchGym Fundamentals | TBD |
| | Oct 16 | Reinforcement Learning for Architecture | TBD |
| **8** | **Oct 21** | **AI for Cache & Memory Hierarchy** | |
| | Oct 21 | Cache Replacement and Prefetching | TBD |
| | Oct 23 | Memory System Design | TBD |
| **9** | **Oct 28** | **AI for Branch Prediction & Control Flow** | |
| | Oct 28 | Neural Branch Prediction | TBD |
| | Oct 30 | Control Flow Optimization | TBD |
| **10** | **Nov 4** | **AI for Processor Microarchitecture** | |
| | Nov 4 | Superscalar Design and Scheduling | TBD |
| | Nov 6 | Out-of-Order Execution Optimization | TBD |
| **11** | **Nov 11** | **AI for Accelerator Design** | |
| | Nov 11 | Neural Architecture Search for Accelerators | TBD |
| | Nov 13 | Domain-Specific Architecture Generation | TBD |

## AI for EDA
*Physical implementation and chip design*

| Week | Date | Topic | Key Papers |
|------|------|-------|------------|
| **12** | **Nov 18** | **AI for Physical Design** | |
| | Nov 18 | DREAMPlace and GPU-Accelerated Placement | TBD |
| | Nov 20 | Routing and Physical Synthesis | TBD |
| **13** | **Nov 25** | **AI for Logic Synthesis & Timing** | |
| | Nov 25 | Logic Synthesis and Optimization | TBD |
| | Nov 27 | *No class - Thanksgiving Break* | |
| **14** | **Dec 2** | **Integration & Future Directions** | |
| | Dec 2 | Industry Perspectives + Project Presentations | Student presentations |

**üìù Projects Due: December 2**

---

## Reading Access

- **Primary Sources**: Papers available through Harvard Library, ACM Digital Library, IEEE Xplore
- **Course Reserves**: Key papers uploaded to course management system
- **Supplemental Materials**: Additional resources linked from course website

## Discussion Format

Each session follows a structured format:
1. **Opening** (10 min): Key takeaways and questions from readings
2. **Deep Dive** (45 min): Structured discussion led by students or instructor  
3. **Matrix Mapping** (15 min): How do these papers fit in our framework?
4. **Synthesis** (5 min): Connections to previous sessions and upcoming topics

---

*Schedule subject to adjustment based on guest speaker availability and emerging research developments.*